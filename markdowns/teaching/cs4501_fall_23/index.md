---
layout: page
title: Optimization 
permalink: /teaching/cs4501_fall_23/index
---

The recent success in deep learning is largely driven by the application of large neural networks.
In this course,
we will cover the foundations of the techniques that are commonly used to train those large neural networks,
namely,
first-order optimization methods.
Those include stochastic gradient descent and its variants.
This course will cover both theoretical analysis and empirical implementation.

WARNING: This course is mathematically heavy but does involve programming.

## Logistics:

- Instructor: [Shangtong Zhang](/)
- Location: TBD   
- Time: Tuesday & Thursday, 14:00 - 15:15  
- TA: TBD 
- Office Hour: 
  - Shangtong: Tuesday & Thursday 15:30 - 16:30 (Rice Hall 422)
- UVACollab: [OPT-CS4501-F23]()
- Prerequisite: TBD
- Textbook: [First-Order Methods in Optimization](https://epubs.siam.org/doi/10.1137/1.9781611974997) by Amir Beck


## Topics:
We aim to cover important results in the first 10 chapters of the textbook.

- Probability 
- Linear algebra 
- Subgradients
- Conjugate functions
- Smoothness and strong convexity
- The proximal operator
- Spectral functions
- Primal and dual projected subgradient methods 
- Mirror descent
- The proximal gradient method

## Grading (tentative):
- Written Assignments
- Coding Assignments

All the written assignments are expected to be **PDF files** generated by LaTeX. 
[Here](/blog/latex) are some tips for LaTeX.

## Schedule:

| Date  |  Comments |
|-------| ----------|
| 08/23 |   |
| 08/25 |  | 
| 08/30 |  |
| 09/01 |  | 
| 09/06 |  | 
| 09/08 | |
| 09/13 |  |        
| 09/15 |            |
| 09/20 |  |          
| 09/22 |            |
| 09/27 | |
| 09/29 |                   |
| 10/04 |  |
| 10/06 | |
| 10/11 |   |
| 10/13 |  |
| 10/18 |                   |
| 10/20 |   |
| 10/25 | |
| 10/27 |  |
| 11/01 |                   |
| 11/03 |                   |
| 11/08 | |
| 11/10 |  |
| 11/15 |  |
| 11/17 |  |
| 11/22 |  |
| 11/24 | |
| 11/29 | |
| 12/01 | |
| 12/06 | |

## Policies:

No late submission is allowed except for medical needs and reasonable career development needs.
See all policies [here](/teaching/policies).