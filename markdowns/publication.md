---
layout: publications 
title: Publications 
permalink: /publication/
---

<sup>*</sup> indicates equal contribution.  <u>Advisees</u> are underlined. <sup>†</sup> indicates equal advising.  &#127881; indicates the works I like most.  

- <span class="rep_pub"></span> [arXiv 2024] [Almost Sure Convergence Rates and Concentration of Stochastic Approximation and Reinforcement Learning with Markovian Noise](https://arxiv.org/abs/2411.13711).  
<u>Xiaochi Qian</u><sup>*</sup>, <u>Zixuan Xie</u><sup>*</sup>, <u>Xinyu Liu</u><sup>*</sup>, **Shangtong Zhang**.  

- <span class="rep_pub"></span> [arXiv 2024] [The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise](https://arxiv.org/abs/2401.07844).  
<u>Shuze Liu</u>, Shuhang Chen, **Shangtong Zhang**.   

- <span class="rep_pub"></span> [arXiv 2024] [Transformers Learn Temporal Difference Methods for In-Context Reinforcement Learning](https://arxiv.org/abs/2405.13861).   
<u>Jiuqi Wang</u><sup>*</sup>, <u>Ethan Blaser</u><sup>*</sup>, Hadi Daneshmand, **Shangtong Zhang**.  
**QuantCo Spotlight Award** at the ICML Workshop on In-Context Learning, 2024.  

- [AAAI 2025] [Efficient Multi-Policy Evaluation for Reinforcement Learning](https://arxiv.org/abs/2408.08706).  
<u>Shuze Liu</u>, <u>Claire Chen</u>, **Shangtong Zhang**.  

- [arXiv 2024] [CRASH: Challenging Reinforcement-Learning Based Adversarial Scenarios For Safety Hardening](https://arxiv.org/abs/2411.16996).  
Amar Kulkarni, **Shangtong Zhang**, Madhur Behl.  

- [arXiv 2024] [Efficient Policy Evaluation with Safety Constraint for Reinforcement Learning](https://arxiv.org/abs/2410.05655).  
<u>Claire Chen</u><sup>*</sup>, <u>Shuze Liu</u><sup>*</sup>, **Shangtong Zhang**.  

- [arXiv 2024] [Doubly Optimal Policy Evaluation for Reinforcement Learning](https://arxiv.org/abs/2410.02226).  
<u>Shuze Liu</u>, <u>Claire Chen</u>, **Shangtong Zhang**.  

- [arXiv 2024] [Almost Sure Convergence of Average Reward Temporal Difference Learning](https://arxiv.org/abs/2409.19546).  
<u>Ethan Blaser</u>, **Shangtong Zhang**.  

- [arXiv 2024] [Almost Sure Convergence of Linear Temporal Difference Learning with Arbitrary Features](https://arxiv.org/abs/2409.12135).  
<u>Jiuqi Wang</u>, **Shangtong Zhang**.  

- [ICML 2024] [Efficient Policy Evaluation with Offline Data Informed Behavior Policy Design](https://arxiv.org/abs/2301.13734).  
<u>Shuze Liu</u>, **Shangtong Zhang**.   

- [arXiv 2023] [Revisiting a Design Choice in Gradient Temporal Difference Learning](https://arxiv.org/abs/2308.01170).  
<u>Xiaochi Qian</u>, **Shangtong Zhang**.   

- [AAAI 2023] [A New Challenge in Policy Evaluation](https://ojs.aaai.org/index.php/AAAI/article/view/26832).  
**Shangtong Zhang**.  

- [ICML 2023] [On the Convergence of SARSA with Linear Function Approximation](https://arxiv.org/abs/2202.06828).  
**Shangtong Zhang**, Remi Tachet des Combes, Romain Laroche.  

- [arXiv 2023] [StarCraft II Unplugged: Large Scale Offline Reinforcement Learning](https://arxiv.org/abs/2308.03526)  
Michael Mathieu<sup>*</sup>, Sherjil Ozair<sup>*</sup>, Srivatsan Srinivasan<sup>*</sup>, Caglar Gulcehre<sup>*</sup>, **Shangtong Zhang**<sup>*</sup>, Ray Jiang<sup>*</sup>, Tom Le Paine<sup>*</sup>, Richard Powell, Konrad Zolna, Julian Schrittwieser, David Choi, Petko Georgiev, Daniel Toyama, Aja Huang, Roman Ring, Igor Babuschkin, Timo Ewalds, Mahyar Bordbar, Sarah Henderson, Sergio Gomez Colmenarejo, Aaron van den Oord, Wojciech Marian Czarnecki, Nando de Freitas, Oriol Vinyals.  

- [JMLR 2022] [Global Optimality and Finite Sample Analysis of Softmax Off-Policy Actor Critic under State Distribution Mismatch](https://arxiv.org/abs/2111.02997).  
**Shangtong Zhang**, Remi Tachet des Combes<sup>†</sup>, Romain Laroche<sup>†</sup>.  

- [JMLR 2022] [Truncated Emphatic Temporal Difference Methods for Prediction and Control](https://arxiv.org/abs/2108.05338).  
**Shangtong Zhang**, Shimon Whiteson.  

- [AAMAS 2022] [A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms](https://arxiv.org/abs/2010.01069).  
**Shangtong Zhang**, Romain Laroche, Harm van Seijen, Shimon Whiteson, Remi Tachet des Combes.  
**Oral Presentation**

- [AAAI 2022] [Learning Expected Emphatic Traces for Deep RL](https://arxiv.org/abs/2107.05405).  
Ray Jiang, **Shangtong Zhang**, Veronica Chelu, Adam White, Hado van Hasselt.  

- [ICML 2021] [Breaking the Deadly Triad with a Target Network](https://arxiv.org/abs/2101.08862).  
**Shangtong Zhang**, Hengshuai Yao, Shimon Whiteson.  

- [ICML 2021] [Average-Reward Off-Policy Policy Evaluation with Function Approximation](https://arxiv.org/abs/2101.02808).  
**Shangtong Zhang**<sup>\*</sup>, Yi Wan<sup>\*</sup>, Richard S. Sutton, Shimon Whiteson.  

- [AAAI 2021] [Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2004.10888).  
**Shangtong Zhang**, Bo Liu, Shimon Whiteson.  

- [NeurIPS 2020] [Learning Retrospective Knowledge with Reverse Reinforcement Learning](https://arxiv.org/abs/2007.06703).  
**Shangtong Zhang**, Vivek Veeriah, Shimon Whiteson.  

- [ICML 2020] [GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values](https://arxiv.org/abs/2001.11113).  
**Shangtong Zhang**, Bo Liu, Shimon Whiteson.  

- [ICML 2020] [Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation](https://arxiv.org/abs/1911.04384).  
**Shangtong Zhang**, Bo Liu, Hengshuai Yao, Shimon Whiteson.  

- [AAMAS 2020] [Deep Residual Reinforcement Learning](https://arxiv.org/abs/1905.01072).  
**Shangtong Zhang**, Wendelin Boehmer, Shimon Whiteson.  
**Best Paper Award**.

- [AAAI 2020] [Mega-Reward: Achieving Human-Level Play without Extrinsic Rewards](https://arxiv.org/abs/1905.04640).  
Yuhang Song, Jianyi Wang, Thomas Lukasiewicz, Zhenghua Xu, **Shangtong Zhang**, Mai Xu.  

- [NeurIPS 2019] [Generalized Off-Policy Actor-Critic](https://arxiv.org/abs/1903.11329).  
**Shangtong Zhang**, Wendelin Boehmer, Shimon Whiteson.  

- [NeurIPS 2019] [DAC: The Double Actor-Critic Architecture for Learning Options](https://arxiv.org/abs/1904.12691).  
**Shangtong Zhang**, Shimon Whiteson.  

- [ICML 2019] [Distributional Reinforcement Learning for](https://arxiv.org/abs/1905.06125) [Efficient Exploration](http://www.ifaamas.org/Proceedings/aamas2019/pdfs/p2117.pdf).  
Borislav Mavrin, **Shangtong Zhang**, Hengshuai Yao, Linglong Kong, Kaiwen Wu, Yaoliang Yu.  
<!-- A short version is accepted as an extended abstract at AAMAS 2019.   -->

- [AAAI 2019] [ACE: An Actor Ensemble Algorithm for Continuous Control with Tree Search](https://arxiv.org/abs/1811.02696).  
**Shangtong Zhang**, Hao Chen, Hengshuai Yao.  
**Spotlight Presentation**

- [AAAI 2019] [QUOTA: The Quantile Option Architecture for Reinforcement Learning](https://arxiv.org/abs/1811.02073).  
**Shangtong Zhang**, Borislav Mavrin, Linglong Kong, Bo Liu, Hengshuai Yao.  
**Oral Presentation**

- [JOSS 2018] [MLPack 3: A Fast, Flexible Machine Learning Library](https://joss.theoj.org/papers/f9fb80cf56e79edd4d87e5cf7c5f1759).  
Ryan R Curtin, Marcus Edel, Mikhail Lozhnikov, Yannis Mentekidis, Sumedh Ghaisas, **Shangtong Zhang**.  

- [ECML-PKDD 2017] [Crossprop: Learning Representations by Stochastic Meta-Gradient Descent in Neural Networks](https://link.springer.com/chapter/10.1007/978-3-319-71249-9_27).  
Vivek Veeriah<sup>\*</sup>, **Shangtong Zhang**<sup>\*</sup>, Richard S. Sutton.  

- [Deep RL Symposium, NIPS 2017] [A Deeper Look at Experience Replay](https://arxiv.org/abs/1712.01275).  
**Shangtong Zhang**, Richard S. Sutton.  

- [Deep RL Symposium, NIPS 2017] [Comparing Deep Reinforcement Learning and Evolutionary Methods in Continuous Control](https://arxiv.org/abs/1712.00006).  
**Shangtong Zhang**, Osmar R. Zaiane.  

- [Hierarchical RL Workshop, NIPS 2017] [A Demon Control Architecture with Off-Policy Learning and Flexible Behavior Policy](https://drive.google.com/file/d/1tV1Lw1fIsQTihSzSvBT206XX2_6UjiRB/view).  
**Shangtong Zhang**, Richard S. Sutton.  

- [ICMR 2015] [A Deep Neural Network for Modeling Music](https://dl.acm.org/citation.cfm?id=2749367).  
Pengjing Zhang, Xiaoqing Zheng, Wenqiang Zhang, Siyan Li, Sheng Qian, Wenqi He, **Shangtong Zhang**, Ziyuan Wang.  
