---
layout: page
title: Topics in Reinforcement Learning
permalink: /teaching/advanced-rl
---

Reinforcement learning (RL) is a powerful framework for solving sequential decision making problems
and has enjoyed tremendous success, e.g., [playing the game of Go](https://www.nature.com/articles/nature16961) and [nuclear fusion control](https://www.nature.com/articles/s41586-021-04301-9).


In this course,
we will dive into some theoretical topics of RL,
such as
* fundamentals of Markov Decision Processes
* off-policy learning with function approximation
* asymptotic and non-asymptotic analysis of representative RL algorithms

You are expected to be comfortable with reading and writing proofs involving linear algebra and probability. 
You are **NOT** expected to know RL. 
We will make sure you can catch up even if you do not know RL before. 
You will be able to catch up with most RL papers easily and be well prepared to do research in RL after this course.

- Instructor: [Shangtong Zhang](/)
- Location: TBA 
- Time: TBA 
- TA: TBA
- Discussion: TBA
- Office Hour: TBA

## Grading (tentative, subject to change):
- Reading assignment (10%):  
There will be several reading assignments and you are required to ask some theoretical questions related to the materials (you do not need to answer them).
- Paper presentation (20%):  
Each student is expected to present a paper focusing on the theoretical results of the paper.
- Project (70%):  
Each student is expected to complete a course project solo.
You will need to submit a project proposal (10%) and a final writeup (60%).
You can choose one of the following three types of projects:
  - Reproduce the proofs of a theoretical paper from this list
  - Investigate a research idea from this list (it might be empirical and/or theoretical)  
  - Propose a new research project by yourself (talk with me first if you choose this one)

<!-- The project can be theoretical but does **NOT** have to. -->
<!-- For example, it can also be empirical investigation or application of some theoretical results in the lecture. -->
<!-- The project does **NOT** have to have positive results.  -->
<!-- Negative results are equally welcomed as long as it answers an interesting question in a scientific way. -->
  <!-- - Project proposal (10%) -->
  <!-- - Midterm report (10%) -->
  <!-- - Final writeup (50%) -->
  <!-- - Project presentation (10%) -->

## Schedule (TBA):

## Resources:
### Books:
- [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)
- [Markov Decision Processes: Discrete Stochastic Dynamic Programming](https://www.amazon.ca/Markov-Decision-Processes-Stochastic-Programming/dp/0471727822)
- [Stochastic Approximation: A Dynamical Systems Viewpoint](https://www.amazon.com/Stochastic-Approximation-Dynamical-Systems-Viewpoint/dp/0521515920)

### Papers (TBA):

### Theses (TBA):